{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eac042e",
   "metadata": {},
   "source": [
    "### Python Implementação Regressão Linear \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "36616434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todos os imports que vou utilizar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c3163b",
   "metadata": {},
   "source": [
    "### Implementação de uma Classe Abstrata Modelo RL\n",
    "Essa classe vai servir de base pros outros modelos que vou criar, sendo eles:\n",
    "- Gradiente Descendente\n",
    "- Gradiente Descendente Estocástico\n",
    "- OLS (Ordinary Least Square)\n",
    "\n",
    "\n",
    "Essa primeira parte do meu código são as classes que vão ser utilizadas, tem o Scaler e as Regresões Lineares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af2aaee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Zscore():\n",
    "    def __init__(self, columnNumber = 2):\n",
    "        self.__means = np.empty(columnNumber)\n",
    "        self.__stds = np.empty(columnNumber)\n",
    "        self.__quantity = 0\n",
    "        \n",
    "    def __setMeans(self, newMeans):\n",
    "        self.__means = newMeans\n",
    "    \n",
    "    def getMeans(self):\n",
    "        return self.__means\n",
    "    \n",
    "    def __setStds(self, newStds):\n",
    "        self.__stds = newStds\n",
    "    \n",
    "    def getStds(self):\n",
    "        return self.__stds\n",
    "    \n",
    "    def __setQuantity(self, newQ):\n",
    "        self.__quantity = newQ\n",
    "    \n",
    "    def getQuantity(self):\n",
    "        return self.__quantity\n",
    "    \n",
    "    def __addValues(self, mu, sigma):\n",
    "        means = self.getMeans()\n",
    "        stds = self.getStds()\n",
    "        quantity = self.getQuantity()\n",
    "        \n",
    "        means[quantity] = mu\n",
    "        stds[quantity] = sigma\n",
    "        \n",
    "        self.__setMeans(means)\n",
    "        self.__setStds(stds)\n",
    "        \n",
    "        self.__setQuantity(quantity + 1)\n",
    "    \n",
    "    def scale(self, data):\n",
    "        rows = data.shape[0]\n",
    "        columns = data.shape[1]\n",
    "        #Utiliza a Normalização Z-score, seria o equivalente ao Standard Scaler\n",
    "        #Recebe um conjunto de dados e Retorna o mesmo conjunto de dados normalizado com média 0 e dp 1\n",
    "        dataScaled = np.empty([rows, 0])\n",
    "        for i in range(columns):\n",
    "            #Esse método faz a normalização coluna por coluna, onde i é o número da coluna\n",
    "            dataColumn = data[:, [i]]\n",
    "\n",
    "            #Cálculo da média e desvio-padrão da coluna que vai ser normalizada\n",
    "            mu = np.mean(dataColumn)\n",
    "            sigma = np.std(dataColumn)\n",
    "\n",
    "            columnScaled = (dataColumn - mu)/sigma\n",
    "            #columnScaled = (xi - mu)/sigma\n",
    "            #operação broadcasting para toda a coluna\n",
    "            dataScaled = np.c_[dataScaled, columnScaled]\n",
    "            \n",
    "            self.__addValues(mu, sigma)\n",
    "            #adiciona a coluna no dataset normalizado\n",
    "        #print(dataScaled)\n",
    "        return dataScaled\n",
    "    \n",
    "    def unscale(self, data, column = -1):\n",
    "        # pensando em implementar um atributo dataset original\n",
    "        # mas esse método tem como função principal fazer o \"unscale\" de novos atributos de um dado escalado\n",
    "        # anteriormente, como por exemplo ŷ que é escalado na normal com base nos dados de y\n",
    "        if column == -1:\n",
    "            mu = self.getMeans()\n",
    "            sigma = self.getStds()\n",
    "            \n",
    "        elif column >= self.getQuantity():\n",
    "            print(\"ERRO: Número de Coluna \", column ,\" Inválida.\")\n",
    "            return\n",
    "            \n",
    "        else:\n",
    "            mu = self.getMeans()[column]\n",
    "            sigma = self.getStds()[column]\n",
    "            \n",
    "        return sigma * data + mu\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0142ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Minmax():\n",
    "    def __init__(self, columnNumber = 2):\n",
    "        self.__mins = np.empty(columnNumber)\n",
    "        self.__maxs = np.empty(columnNumber)\n",
    "        self.__quantity = 0\n",
    "        \n",
    "    def __setMins(self, newMins):\n",
    "        self.__mins = newMins\n",
    "    \n",
    "    def getMins(self):\n",
    "        return self.__mins\n",
    "    \n",
    "    def __setMaxs(self, newMaxs):\n",
    "        self.__maxs = newMaxs\n",
    "    \n",
    "    def getMaxs(self):\n",
    "        return self.__maxs\n",
    "    \n",
    "    def __setQuantity(self, newQ):\n",
    "        self.__quantity = newQ\n",
    "    \n",
    "    def getQuantity(self):\n",
    "        return self.__quantity\n",
    "    \n",
    "    def __addValues(self, newmin, newmax):\n",
    "        mins = self.getMins()\n",
    "        maxs = self.getMaxs()\n",
    "        quantity = self.getQuantity()\n",
    "        \n",
    "        mins[quantity] = newmin\n",
    "        maxs[quantity] = newmax\n",
    "        \n",
    "        self.__setMins(mins)\n",
    "        self.__setMaxs(maxs)\n",
    "        \n",
    "        self.__setQuantity(quantity + 1)\n",
    "    \n",
    "    def scale(self, data):\n",
    "        rows = data.shape[0]\n",
    "        columns = data.shape[1]\n",
    "        \n",
    "        dataScaled = np.empty([rows, 0])\n",
    "        for i in range(columns):\n",
    "            dataColumn = data[:, [i]]\n",
    "            minimum = min(dataColumn)\n",
    "            maximum = max(dataColumn)\n",
    "            \n",
    "            columnScaled = (dataColumn - minimum)/(maximum - minimum)\n",
    "            dataScaled = np.c_[dataScaled, columnScaled]\n",
    "            self.__addValues(minimum, maximum)\n",
    "        return dataScaled\n",
    "    \n",
    "    def unscale(self, data, column = -1):\n",
    "        # pensando em implementar um atributo dataset original\n",
    "        # mas esse método tem como função principal fazer o \"unscale\" de novos atributos de um dado escalado\n",
    "        # anteriormente, como por exemplo ŷ que é escalado na normal com base nos dados de y\n",
    "        if column == -1:\n",
    "            minimum = self.getMins()\n",
    "            maximum = self.getMaxs()\n",
    "            \n",
    "        elif column >= self.getQuantity():\n",
    "            print(\"ERRO: Número de Coluna \", column ,\" Inválida.\")\n",
    "            \n",
    "        else:\n",
    "            minimum = self.getMins()[column]\n",
    "            maximum = self.getMaxs()[column]\n",
    "            \n",
    "        return (data * (maximum - minimum)) + minimum\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0917a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class LinearRegression(ABC):\n",
    "    def __init__(self, xSize = 1, weights = []):\n",
    "        #xSize representa o número de colunas que vai ser usado nessa regressão linear como X\n",
    "        #se será uma simples, teremos xSize com valor igual a 1, que é a base\n",
    "        #mais que isso o usuário deve informar\n",
    "        self.__xSize = xSize\n",
    "        if weights == []:\n",
    "            self.__weights = np.zeros(xSize + 1)\n",
    "        elif xSize == weights.shape[0] - 1:\n",
    "            self.__weights = np.array(weights)\n",
    "        else:\n",
    "            print(\"ERRO: Vetor peso inicial de tamanho \", xSize, \" enquanto o número de multiplicadores é \", weights.shape[0] - 1)\n",
    "            return\n",
    "        \n",
    "    def setxSize(self, newXs):\n",
    "        self.xSize = newXs\n",
    "    \n",
    "    def getXsize(self):\n",
    "        return self.__xSize\n",
    "        \n",
    "    def setWeights(self, newW):\n",
    "        self.__weights = newW\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self.__weights\n",
    "            \n",
    "    def train(self, X, Y, l2 = 0):\n",
    "        pass\n",
    "    def test(self, X):\n",
    "        #aqui eu to passando o tipo de erro mas ainda to decidindo se vou manter isso ou não\n",
    "        pass\n",
    "    def polinomial(self, data, graus):\n",
    "        Y = data[:, data.shape[1] - 1]\n",
    "        data = data[:, :data.shape[1] - 1]\n",
    "        newdata = data.copy()\n",
    "        #um método para tornar uma regressão linear em polinomial\n",
    "        for grau in range(2,graus +1):\n",
    "            #não mexe no Y\n",
    "            for colunaN in range(data.shape[1]):\n",
    "                coluna = data[:, colunaN]\n",
    "                novaColuna = coluna ** grau\n",
    "                newdata = np.c_[newdata, novaColuna]\n",
    "                #print(coluna, grau)\n",
    "        data = np.c_[newdata, Y]\n",
    "        #print(data)\n",
    "        self.setxSize(self.getxSize() * graus)\n",
    "        w = np.zeros((self.getWeights().shape[0] - 1) * graus + 1)\n",
    "        self.setWeights(w)\n",
    "        #print(w)\n",
    "        return data\n",
    "    def calcErro(self, Y_hat, Y, N):\n",
    "        resultados = np.sqrt(((Y_hat - Y)**2).sum()/N)\n",
    "        return resultados\n",
    "\n",
    "class OrdinaryLeastSquare(LinearRegression):\n",
    "\n",
    "    def __init__(self, xSize = 1, weights = []):\n",
    "        super().__init__(xSize, weights)\n",
    "        \n",
    "    def setxSize(self, newXs):\n",
    "        self._LinearRegression__xSize = newXs\n",
    "    \n",
    "    def getxSize(self):\n",
    "        return self._LinearRegression__xSize\n",
    "        \n",
    "    def setWeights(self, newW):\n",
    "        self._LinearRegression__weights = newW\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self._LinearRegression__weights\n",
    "    \n",
    "    def train(self, X, Y, l2 = 0):\n",
    "        #X = np.array(X)\n",
    "        #Y = np.array(Y)\n",
    "        if X.shape[1] != (self.getWeights()).shape[0] - 1:\n",
    "            print(\"ERRO: tamanho de X \", X.shape[1] ,\"não condiz com a quantidade de pesos multiplicadores \", self.getWeights().shape[0] - 1)\n",
    "            return\n",
    "        if Y.shape[1] != 1:\n",
    "            print(\"ERRO: tamanho de Y maior diferente do que 1, essa é uma regressão univariada, utilize apenas Y size = 1\")\n",
    "            return\n",
    "        I = np.eye(self.getXsize())\n",
    "        moorePenroseMatrix = np.linalg.inv(X.T @ X + l2 * I) @ X.T\n",
    "        \n",
    "        # o OLS utiliza o peso como [[w1], [w2]] por exemplo\n",
    "        # mas para manter o padrão de peso que vou usar em todas as RLs como [w0, w1, w2] eu faço essa mudancinha\n",
    "        newW = (moorePenroseMatrix @ Y).flatten()\n",
    "        newW = np.insert(newW, 0, 0)\n",
    "        self.setWeights(newW)\n",
    "    # vou pensar ainda se vou calcular o erro em test mesmo ou se vou mudar\n",
    "    def test(self, X):\n",
    "        # esse W, pega os pesos na forma de [w0, w1, w2, w3] ignora o w0 pega o resto e faz\n",
    "        # ficar [[w1], [w2], [w3]] para ser utilizado no OLS\n",
    "        #print(self.getWeights().shape[0])\n",
    "        W = self.getWeights()[1:].reshape([self.getWeights().shape[0] - 1,1])\n",
    "        Yhat = X @ W\n",
    "        #print(W)\n",
    "        #print(self.getWeights())\n",
    "        #Yhat = sigma * Yhat + mu\n",
    "        #Y = sigma * Y + mu\n",
    "        #MSE = (Yhat - Y) ** 2\n",
    "        #print(\"testando: \",Yhat)\n",
    "        \n",
    "        return Yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b2581060",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent(LinearRegression):\n",
    "\n",
    "    def __init__(self, xSize = 1, weights = []):\n",
    "        super().__init__(xSize, weights)\n",
    "        \n",
    "    def setxSize(self, newXs):\n",
    "        self._LinearRegression__xSize = newXs\n",
    "    \n",
    "    def getxSize(self):\n",
    "        return self._LinearRegression__xSize\n",
    "        \n",
    "    def setWeights(self, newW):\n",
    "        self._LinearRegression__weights = newW\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self._LinearRegression__weights\n",
    "    \n",
    "    def train(self, X, Y, alpha = 0.1, weights = [], numberofIterations = 200, l2 = 0):\n",
    "        if weights == []:\n",
    "            weights = self.getWeights() + 0.5\n",
    "        X = np.c_[np.ones([X.shape[0]]), X]\n",
    "        N = X.shape[0]\n",
    "        # adicionando uma coluna de 1's na coluna0 de X\n",
    "        # posso mudar esse for para ser uma condição enviada em forma de lambda func dps\n",
    "        for T in range(0, numberofIterations):\n",
    "            Ypredict = np.empty([0])\n",
    "            #criando as \"predições\" que serão utilizadas para melhor o W\n",
    "            e = np.empty([0])\n",
    "            for i in range(N): # esse for é para gerar os yi's, calculando eles linha por linha\n",
    "                temporaryY = (weights * X[i, :]).sum() # somando w0 + w1 * x1 + ... + wn * xn\n",
    "                Ypredict = np.insert(Ypredict, Ypredict.shape[0], temporaryY) # adicionando o Yp no lugar certo\n",
    "            Ypredict = Ypredict.reshape(-1,1) # mudando o shape dele de [1,2,3] para [[1], [2], [3]]\n",
    "            e = Y - Ypredict # calculando o e = (y - ŷ)\n",
    "            # separa o 0 por causa do termo de regularização\n",
    "            weights[0] = weights[0] + (alpha/N * np.sum(e * X[:, [0]]))\n",
    "            for index in range(1, weights.shape[0]):\n",
    "                weights[index] = weights[index] + (alpha/N * np.sum(e * X[:, [index]]) - l2 * weights[index])\n",
    "                # recalculando os pesos\n",
    "        self.setWeights(weights)\n",
    "            \n",
    "    def test(self, X):\n",
    "        X = np.c_[np.ones([X.shape[0]]), X]\n",
    "        weights = self.getWeights()\n",
    "        Ypredict = np.empty([0])\n",
    "        for i in range(X.shape[0]):\n",
    "            Ypredict = np.insert(Ypredict, Ypredict.shape[0],(X[i, :] * weights).sum())\n",
    "        Ypredict = Ypredict.reshape(-1,1)\n",
    "        #print(Ypredict)\n",
    "        return Ypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3636a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticGradientDescent(LinearRegression):\n",
    "    def __init__(self, xSize = 1, weights = []):\n",
    "        super().__init__(xSize, weights)\n",
    "        \n",
    "    def setxSize(self, newXs):\n",
    "        self._LinearRegression__xSize = newXs\n",
    "    \n",
    "    def getxSize(self):\n",
    "        return self._LinearRegression__xSize\n",
    "        \n",
    "    def setWeights(self, newW):\n",
    "        self._LinearRegression__weights = newW\n",
    "    \n",
    "    def getWeights(self):\n",
    "        return self._LinearRegression__weights\n",
    "    \n",
    "    def train(self, X, Y, alpha = 0.1, weights = [], numberofIterations = 200, l2 = 0):\n",
    "        if weights == []:\n",
    "            weights = self.getWeights() + 0.5\n",
    "        X = np.c_[np.ones([X.shape[0]]), X]\n",
    "        Ypredict = -1\n",
    "        #criando as \"predições\" que serão utilizadas para melhor o W\n",
    "        e = -1\n",
    "        for i in range(numberofIterations):\n",
    "            randomLine = np.random.randint(0, X.shape[0])\n",
    "            #no estocastico invés de pegarmos todos os X e depois fazer a média nós pegamos apenas um X aleatório\n",
    "            #print(\"Y = \", weights, \" * \", X[randomLine])\n",
    "            Ypredict = (weights * X[randomLine]).sum()\n",
    "            #print(\"Resultado: \", Ypredict)\n",
    "            e = Y[randomLine] - Ypredict\n",
    "            weights[0] = weights[0] + alpha *( (e * X[[randomLine], [0]]))\n",
    "            for index in range(1, weights.shape[0]):\n",
    "                #print(\"Valor Sorteado: \", randomLine, \"/n\", \"W = \", weights[index] ,' + ',alpha, \" * \", e, \" * \", X[[randomLine], [index]])\n",
    "                # wi = wi + alpha * (e * xi)\n",
    "                weights[index] = weights[index] + alpha *( (e * X[[randomLine], [index]]) - l2 * weights[index] )\n",
    "        self.setWeights(weights)\n",
    "            \n",
    "    def test(self, X):\n",
    "        #teste padrão\n",
    "        X = np.c_[np.ones([X.shape[0]]), X]\n",
    "        weights = self.getWeights()\n",
    "        Ypredict = np.empty([0])\n",
    "        for i in range(X.shape[0]):\n",
    "            Ypredict = np.insert(Ypredict, Ypredict.shape[0],(X[i, :] * weights).sum())\n",
    "        Ypredict = Ypredict.reshape(-1,1)\n",
    "        #print(Ypredict)\n",
    "        return Ypredict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "beecbb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo os datasets da lista1\n",
    "\n",
    "dataset = np.genfromtxt('artificial1d.csv', delimiter=',')\n",
    "\n",
    "dataset2 = np.genfromtxt('california.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0d9ad259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def questao1(data):\n",
    "    X = data[:, [0]]\n",
    "    Y = data[:, [1]]\n",
    "    \n",
    "    retaX = np.linspace(-1, 1, 100)\n",
    "    \n",
    "    resultados = np.array([-1,-1,-1], dtype = np.double)\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize = (7, 16), nrows = 3)\n",
    "    \n",
    "    GD = GradientDescent()\n",
    "    SGD = StochasticGradientDescent()\n",
    "    OLS = OrdinaryLeastSquare()\n",
    "    \n",
    "    GD.train(X, Y, numberofIterations = 200)\n",
    "    SGD.train(X, Y, numberofIterations = 200)\n",
    "    OLS.train(X, Y)\n",
    "    \n",
    "    predicao = GD.test(X)\n",
    "    resultados[0] = ((predicao - Y)**2).sum()/X.shape[0]\n",
    "    \n",
    "    predicao = SGD.test(X)\n",
    "    resultados[1] = ((predicao - Y)**2).sum()/X.shape[0]\n",
    "    \n",
    "    predicao = OLS.test(X)\n",
    "    resultados[2] = ((predicao - Y)**2).sum()/X.shape[0]\n",
    "    \n",
    "    fig.tight_layout(pad = 5)\n",
    "\n",
    "    axes[0].plot(X, Y, \"ro\")\n",
    "    axes[0].set_title((\"Gradiente Descendente.\\nMSE = \" + str(round(resultados[0], 6))))\n",
    "    W = GD.getWeights()\n",
    "    print(W)\n",
    "    retaY = retaX * W[1] + W[0] \n",
    "    axes[0].plot(retaX, retaY, 'b-')\n",
    "    \n",
    "    axes[1].plot(X, Y, \"ro\")\n",
    "    axes[1].set_title((\"Gradiente Descendente Estocástico.\\nMSE = \" + str(round(resultados[1], 6))))\n",
    "    W = SGD.getWeights()\n",
    "    print(W)\n",
    "    retaY = retaX * W[1] + W[0]\n",
    "    axes[1].plot(retaX, retaY, 'b-')\n",
    "    \n",
    "    axes[2].plot(X, Y, \"ro\")\n",
    "    axes[2].set_title((\"Mínimos Quadrados Ordinários(OLS).\\nMSE = \" + str(round(resultados[2], 6))))\n",
    "    W = OLS.getWeights()\n",
    "    print(W)\n",
    "    retaY = retaX * W[1] + W[0]\n",
    "    axes[2].plot(retaX, retaY, 'b-')\n",
    "    \n",
    "    # fig.savefig(\".//Gráficos//plotQ1.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ea87a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividirTreinoTeste(data, percentOfTrain):\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.permutation(len(data))\n",
    "    \n",
    "    #dividindo em treino e teste\n",
    "    indicesTreino = indices[:int(len(data)*percentOfTrain)]\n",
    "    indicesTeste = indices[int(len(data)*percentOfTrain):]\n",
    "    \n",
    "    treino = data[indicesTreino,:]\n",
    "    teste = data[indicesTeste,:]\n",
    "    \n",
    "    return treino, teste\n",
    "\n",
    "def dividirTreinoTesteIndice(data, percentOfTrain):\n",
    "    indices = np.random.permutation(len(data))\n",
    "    \n",
    "    #dividindo em treino e teste\n",
    "    indicesTreino = indices[:int(len(data)*percentOfTrain)]\n",
    "    indicesTeste = indices[int(len(data)*percentOfTrain):]\n",
    "    \n",
    "    return indicesTreino, indicesTeste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6b82f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def questao2(data):\n",
    "    data = np.array(data)\n",
    "    valoresteste = []\n",
    "    valorestreino = []\n",
    "    \n",
    "    indicesTreino, indicesTeste = dividirTreinoTesteIndice(data, 0.8)\n",
    "    \n",
    "    for i in range(1, 14):\n",
    "        # não vou explicar muito desse código, ele acaba sendo bem intuitivo\n",
    "        normalizer = Zscore(8 * i + 1)\n",
    "        \n",
    "        # o professor especifica \"Normalize antes de criar os regressores Polinomiais\"\n",
    "        # nao entendi o que era os regressores Polinomiais, se isso se aplica à criar os atributos polinomiais\n",
    "        # quando utilizava o Scaler depois de criar os polinomios\n",
    "        # eu tive problemas de Erros GIGANTESCOS, não entendi muito bem o porque\n",
    "        # Resolvi deixar assim pois funcionou melhor e mais intuitivamente para mim\n",
    "        \n",
    "        OLS = OrdinaryLeastSquare(8)\n",
    "        \n",
    "        dataPolinomial = OLS.polinomial(data, i)\n",
    "        dataEscalada = normalizer.scale(dataPolinomial)\n",
    "        \n",
    "        treino = dataEscalada[indicesTreino,:]\n",
    "        teste = dataEscalada[indicesTeste,:]\n",
    "        \n",
    "        #dividindo x e y\n",
    "        xtreino = treino[:, :treino.shape[1] - 1]\n",
    "        xteste = teste[:, :teste.shape[1] - 1]    \n",
    "\n",
    "        ytreino = treino[:, [treino.shape[1] - 1]]\n",
    "        yteste = teste[:, [teste.shape[1] - 1]]\n",
    "\n",
    "        OLS.train(xtreino, ytreino)\n",
    "\n",
    "        predteste = OLS.test(xteste)\n",
    "        predtreino = OLS.test(xtreino)\n",
    "        \n",
    "        predteste = normalizer.unscale(predteste, teste.shape[1] - 1)\n",
    "        predtreino = normalizer.unscale(predtreino, teste.shape[1] - 1 )\n",
    "        \n",
    "        yteste = normalizer.unscale(yteste, teste.shape[1] - 1)\n",
    "        ytreino = normalizer.unscale(ytreino, teste.shape[1] - 1)\n",
    "        \n",
    "        #print(ytreino[0:5])\n",
    "        #print(data[indicesTreino, 8])\n",
    "        \n",
    "        valoresteste.append(OLS.calcErro(predteste, yteste, 200))\n",
    "        valorestreino.append(OLS.calcErro(predtreino, ytreino, 800))\n",
    "        #calc erro já calcula o RMSE\n",
    "        \n",
    "    #print(valoresteste)\n",
    "    #print(valorestreino)\n",
    "    plotGraficos(valoresteste, valorestreino,\n",
    "                 \"Gráfico da Função Custo RMSE - (Raiz do Erro Quadrado Médio)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "812359d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pra poupar o esforço de ter que mudar a funcao questao2 para fazer os dois ao mesmo tempo eu refiz ela aqui\n",
    "#so que com o termo de regularização, fiz isso pois era mais fácil\n",
    "def questao2regularizada(data):\n",
    "    data = np.array(data)\n",
    "    valoresteste = []\n",
    "    valorestreino = []\n",
    "    \n",
    "    indicesTreino, indicesTeste = dividirTreinoTesteIndice(data, 0.8)\n",
    "    # invés de dividir no loop resolvi dividir os indices para ter os mesmos sets de treino e teste para todos\n",
    "    # os valores polinomiais, poderia fazer isso setando o randomseed igual, mas isso piorava minha análise\n",
    "    \n",
    "    for i in range(1, 14):\n",
    "        # não vou explicar muito desse código, ele acaba sendo bem intuitivo\n",
    "        normalizer = Minmax(8 * i + 1)\n",
    "        \n",
    "        # o professor especifica \"Normalize antes de criar os regressores Polinomiais\"\n",
    "        # nao entendi o que era os regressores Polinomiais, se isso se aplica à criar os atributos polinomiais\n",
    "        # quando utilizava o Scaler depois de criar os polinomios\n",
    "        # eu tive problemas de Erros GIGANTESCOS, não entendi muito bem o porque\n",
    "        # Resolvi deixar assim pois funcionou melhor e mais intuitivamente para mim\n",
    "        \n",
    "        OLS = OrdinaryLeastSquare(8)\n",
    "        \n",
    "        dataPolinomial = OLS.polinomial(data, i)\n",
    "        dataEscalada = normalizer.scale(dataPolinomial)\n",
    "        \n",
    "        treino = dataEscalada[indicesTreino,:]\n",
    "        teste = dataEscalada[indicesTeste,:]\n",
    "        \n",
    "        #dividindo x e y\n",
    "        xtreino = treino[:, :treino.shape[1] - 1]\n",
    "        xteste = teste[:, :teste.shape[1] - 1]    \n",
    "\n",
    "        ytreino = treino[:, [treino.shape[1] - 1]]\n",
    "        yteste = teste[:, [teste.shape[1] - 1]]\n",
    "\n",
    "        OLS.train(xtreino, ytreino, l2 = 0.01)\n",
    "\n",
    "        predteste = OLS.test(xteste)\n",
    "        predtreino = OLS.test(xtreino)\n",
    "        \n",
    "        predteste = normalizer.unscale(predteste, teste.shape[1] - 1)\n",
    "        predtreino = normalizer.unscale(predtreino, teste.shape[1] - 1 )\n",
    "        \n",
    "        yteste = normalizer.unscale(yteste, teste.shape[1] - 1)\n",
    "        ytreino = normalizer.unscale(ytreino, teste.shape[1] - 1)\n",
    "        \n",
    "        valoresteste.append(OLS.calcErro(predteste, yteste, 200))\n",
    "        valorestreino.append(OLS.calcErro(predtreino, ytreino, 800))\n",
    "        #calc erro já calcula o RMSE\n",
    "        \n",
    "    #print(valoresteste)\n",
    "    #print(valorestreino)\n",
    "    plotGraficos(valoresteste, valorestreino,\n",
    "                 \"Gráfico da Função Custo Regularizada RMSE - (Raiz do Erro Quadrado Médio)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d2ef330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "def plotGraficos(valoresteste, valorestreino, title):\n",
    "    plt.style.use('_mpl-gallery')\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 6))\n",
    "    \n",
    "    x = np.arange(1, 14)\n",
    "   \n",
    "    ax.plot(x,valorestreino, \"b-\", linewidth = 2, label = \"Treino\")\n",
    "    blue = mpatches.Patch(color='blue', label='Treino')\n",
    "    #----------------------------------------------------------------#\n",
    "    ax.plot(x, valoresteste, \"r-\", linewidth = 2, label = \"Teste\")\n",
    "    red = mpatches.Patch(color='red', label='Teste')\n",
    "    \n",
    "    plt.title(title, fontsize = 18)\n",
    "    ax.set(xlim=(1, 13.5), xticks=np.arange(1, 13.5))\n",
    "    ax.legend(handles=[red, blue], fontsize = 13)\n",
    "    #funcao so para facilitar o plot dos gráficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "15c1b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questao2(dataset2)\n",
    "questao2regularizada(dataset2)\n",
    "#acredito que teja pronto, ultima revisada tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba5a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6ce3c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTE QUE EU FIZ PARA VER SE A POLINOMIAL FUNCIONAVA DIREITINHO, RESOLVI DEIXAR AQUI NO FIM SÓ POR DEIXAR MESMO\n",
    "def teste(data):\n",
    "    data = np.array(data)\n",
    "    data2 = np.array(data)\n",
    "    data3 = np.array(data)\n",
    "    \n",
    "    GD = GradientDescent()\n",
    "    GD2 = GradientDescent()\n",
    "    OLS = OrdinaryLeastSquare()\n",
    "    \n",
    "    data = GD.polinomial(data, 13)\n",
    "    data2 = GD2.polinomial(data2, 13)\n",
    "    data3 = OLS.polinomial(data3, 13)\n",
    "    \n",
    "    treino, teste = dividirTreinoTeste(data, 1.0)\n",
    "    \n",
    "    #dividindo x e y\n",
    "    xtreino = data[:, :treino.shape[1] - 1]\n",
    "    xteste = teste[:, :teste.shape[1] - 1]\n",
    "    \n",
    "    ytreino = data[:, [treino.shape[1] - 1]]\n",
    "    yteste = teste[:, [teste.shape[1] - 1]]\n",
    "    \n",
    "    GD2.train(xtreino, ytreino, alpha = 0.9 ,numberofIterations = 2000)\n",
    "    GD.train(xtreino, ytreino, alpha = 0.9 ,numberofIterations = 2000, l2 = 0.15)\n",
    "    OLS.train(xtreino, ytreino, l2 = 0.15)\n",
    "    \n",
    "    #pred = GD.test(xteste)\n",
    "    #print(GD.getWeights())\n",
    "    \n",
    "    #resultados = np.sqrt(((pred - yteste)**2).sum()/teste.shape[0])\n",
    "    \n",
    "    retaX = np.linspace(-1, 1, 100)    \n",
    "    retaY = np.zeros(100)\n",
    "    retaY2 = np.zeros(100)\n",
    "    retaY3 = np.zeros(100)\n",
    "    \n",
    "    for i in range(14):\n",
    "        retaY += retaX ** i * GD.getWeights()[i]\n",
    "        retaY2 += retaX ** i * GD2.getWeights()[i]\n",
    "        retaY3 += retaX ** i * OLS.getWeights()[i]\n",
    "    plt.plot(xtreino[:, 0], ytreino, 'ro')\n",
    "    plt.plot(retaX, retaY, 'b-')\n",
    "    plt.plot(retaX, retaY2, 'g-')\n",
    "    plt.plot(retaX, retaY3, 'y-')\n",
    "    print(GD.getWeights())\n",
    "    print(GD2.getWeights())\n",
    "    print(OLS.getWeights())\n",
    "    plt.show()\n",
    "    \n",
    "    #print(resultados)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
